{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S005icLa54sz"
      },
      "source": [
        "# Weapon Detector\n",
        "\n",
        "В инструменте используется Object Detection API и модель [RetinaNet](https://arxiv.org/abs/1708.02002) для обнаружения объектов оружия, которую можно переобучить, используя минимальный набор учебных изображений.\n",
        "\n",
        "RetinaNet - одна из лучших одноступенчатых моделей обнаружения объектов, которая хорошо зарекомендовала себя при работе с плотными и мелкомасштабными объектами.\n",
        "\n",
        "Модель была представлена Facebook AI Research для решения проблемы обнаружения плотных объектов. Она была разработана для устранения несбалансированности и противоречивости одноступенчатых систем обнаружения объектов, таких как YOLO и SSD, при работе с классами переднего и заднего плана.\n",
        "\n",
        "По сути, оригинальная сеть RetinaNet является составной сетью, состоящей из:\n",
        "\n",
        "* Backbone – основная (базовая) сеть, служащая для извлечения признаков из поступающего на вход изображения. Данная часть сети является вариативной и в её основу могут входить классификационные нейросети, такие как ResNet, VGG, EfficientNet и другие\n",
        "\n",
        "* Feature Pyramid Net (FPN) – свёрточная нейронная сеть, построенная в виде пирамиды, служащая для объединения достоинств карт признаков нижних и верхних уровней сети, первые имеют высокое разрешение, но низкую семантическую, обобщающую способность; вторые — наоборот\n",
        "\n",
        "* Classification Subnet – подсеть, извлекающая из FPN информацию о классах объектов, решая задачу классификации\n",
        "\n",
        "* Regression Subnet – подсеть, извлекающая из FPN информацию о координатах объектов на изображении, решая задачу регрессии\n",
        "\n",
        "<img src='https://i115.fastpic.ru/big/2021/0628/5b/a64b2f27cf2dca5feae0b3097599be5b.png' alt='model'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d18PZkr97yBN"
      },
      "source": [
        "Прежде всего, необходимо клонировать Tensorflow Model Garden и установить Tensorflow 2 [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfBAqkGZ5G_s",
        "outputId": "ca41d925-507c-4986-e880-c7f53a4c2250"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./models/\n",
        "\n",
        "!git clone --depth 1 https://github.com/tensorflow/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qc9s0rp8FKE"
      },
      "source": [
        "Установка Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOXwjFqu78u9",
        "outputId": "dcfdb40b-f627-41d9-a7f2-4dc618d18b85"
      },
      "outputs": [],
      "source": [
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python3 -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ofPLcj8YPK"
      },
      "source": [
        "## Импорт библиотек\n",
        "\n",
        "Импорт библиотек, необходимых для проекта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q28W5_U_8WT1",
        "outputId": "0797cf5e-c678-4f01-a8cd-a2e7c03a825f"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import Object Detection API packages\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils  import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbgsQNMA8x01"
      },
      "source": [
        "## Утилиты\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFd6HVVp8nLt"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    \n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "    (im_width, im_height) = image.size\n",
        "    \n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "    \n",
        "    image_np_with_annotations = image_np.copy()\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_annotations,\n",
        "        boxes,\n",
        "        classes,\n",
        "        scores,\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        min_score_thresh=0.8)\n",
        "    \n",
        "    if image_name:\n",
        "        plt.imsave(image_name, image_np_with_annotations)\n",
        "    \n",
        "    else:\n",
        "        plt.imshow(image_np_with_annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGJVbG3o-NNB"
      },
      "source": [
        "## Визуализация данных изображений оружия\n",
        "\n",
        "Для обучения будут использованы 4 изображения оружия."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "H_3VqKtA-HOD",
        "outputId": "3ec29e3d-a2d4-4918-d723-e1b218ccc134"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "train_image_dir = './training'\n",
        "train_images_np = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "\n",
        "    # define the path (string) for each image\n",
        "    image_path = os.path.join('./training/gun_'+str(i)+'.jpg')\n",
        "    print(image_path)\n",
        "\n",
        "    # load images into numpy arrays and append to a list\n",
        "    train_images_np.append(load_image_into_numpy_array(image_path))\n",
        "\n",
        "# configure plot settings via rcParams\n",
        "plt.rcParams['axes.grid'] = False\n",
        "plt.rcParams['xtick.labelsize'] = False\n",
        "plt.rcParams['ytick.labelsize'] = False\n",
        "plt.rcParams['xtick.top'] = False\n",
        "plt.rcParams['xtick.bottom'] = False\n",
        "plt.rcParams['ytick.left'] = False\n",
        "plt.rcParams['ytick.right'] = False\n",
        "plt.rcParams['figure.figsize'] = [14, 7]\n",
        "\n",
        "# plot images\n",
        "for idx, train_image_np in enumerate(train_images_np):\n",
        "    plt.subplot(1, 4, idx+1)\n",
        "    plt.imshow(train_image_np)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kja0YP7nBUe5"
      },
      "source": [
        "## Подготовка данных для обучения\n",
        "\n",
        "В процессе работы будут создаваться ячейки для установления объектов поиска. Другими словами, необходимо обвести объекты на изображениях, данные которых будут использоваться для последующего обучения. Для этих целей будет использоваться **colab_utils.annotate** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "3u4JFRz5_Qmy",
        "outputId": "9b8d42e5-7f2f-4eeb-ba52-55117119a24e"
      },
      "outputs": [],
      "source": [
        "# Define the list of ground truth boxes\n",
        "gt_boxes = []\n",
        "colab_utils.annotate(train_images_np, box_storage_pointer=gt_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeL4dC9aCSWo"
      },
      "source": [
        "## Определение словаря указателя категорий\n",
        "\n",
        "Необходимо указать модели, а точнее какой идентификатор класса присвоить категории \"имеет оружие\", и какое \"имя\" связать с этим целочисленным идентификатором."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLGOoiTgB1qC",
        "outputId": "22e22e3d-0c2e-4aab-a2ef-d37bfeaaf553"
      },
      "outputs": [],
      "source": [
        "has_gun_class_id = 1\n",
        "\n",
        "category_index = {\n",
        "    has_gun_class_id: \n",
        "        {\n",
        "            'id': has_gun_class_id, \n",
        "            'name': 'has gun'\n",
        "        }\n",
        "}\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "print(category_index[has_gun_class_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLs8tvsECwvj"
      },
      "source": [
        "Теперь необходимо проветси некоторую предварительную обработку данных, чтобы они были правильно отформатированы перед подачей в модель:\n",
        "\n",
        "* Преобразовать метки классов в одноточечные представления.\n",
        "* Преобразовать все (т.е. учебные изображения, gt-боксы и метки классов) в тензоры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhSsjQ1tCnIU",
        "outputId": "c09be55c-7872-4c55-f7ea-f93cc73fc690"
      },
      "outputs": [],
      "source": [
        "label_id_offset = 1\n",
        "train_image_tensors = []\n",
        "gt_classes_one_hot_tensors = []\n",
        "gt_box_tensors = []\n",
        "\n",
        "for (train_image_np, gt_box_np) in zip(train_images_np, gt_boxes):\n",
        "  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor( train_image_np, dtype=tf.float32), axis=0))\n",
        "    \n",
        "  gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))\n",
        "    \n",
        "  zero_indexed_groundtruth_classes = tf.convert_to_tensor(np.ones(shape=[gt_box_np.shape[0]], dtype=np.int32) - label_id_offset)\n",
        "    \n",
        "  gt_classes_one_hot_tensors.append(tf.one_hot(zero_indexed_groundtruth_classes, num_classes))\n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mMiGyKLDUel"
      },
      "source": [
        "## Загрузка контрольных точек с предварительно обученными весами\n",
        "\n",
        "Далее нужно скачать [RetinaNet](https://arxiv.org/abs/1708.02002) и скопировать его в каталог обнаружения объектов. Загрузим сжатую контрольную точку SSD Resnet 50 версии 1, 640 x 640. Затем распакуем загруженный файл и переместим распакованную контрольную точку в models/research/object_detection/test_data/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am7kojcSC-FA",
        "outputId": "0b34348c-2078-4995-da2c-944b7bc9b3f4"
      },
      "outputs": [],
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "\n",
        "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "\n",
        "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfNzZA9pD804"
      },
      "source": [
        "## Настройка модели\n",
        "\n",
        "\n",
        "#### pipeline_config\n",
        "- В Colab, слева от оглавления, выбираем значок папки, чтобы отобразить браузер файлов для текущего рабочего пространства.  \n",
        "- Переходим в папку `models/research/object_detection/configs/tf2`. В папке есть несколько файлов с расширением .config.  \n",
        "- Находим файл, соответствующий ssd resnet 50 version 1 640x640.\n",
        "- Устанавливаем `pipeline_config` в строку, содержащую полный путь к файлу конфигурации resnet, другими словами: `models/research/.../... .config`\n",
        "\n",
        "#### configs\n",
        "Если изучить модуль [config_util](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/config_util.py) который был исопртирован ранее, то можно найти функцию:\n",
        "\n",
        "```\n",
        "def get_configs_from_pipeline_file(pipeline_config_path, config_override=None):\n",
        "```\n",
        "- Необходимо использовать эту функцию, для загрузки конфигурации из `pipeline_config`.\n",
        "  - после этого `configs` будет содержать словарь.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojyG1PrtD3vc",
        "outputId": "b7a91bfd-2b23-47cd-ee9f-6a659738db6d"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "pipeline_config = \"/content/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config\"\n",
        "\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "\n",
        "# Read in the object stored at the key 'model' of the configs dictionary\n",
        "model_config = configs['model']\n",
        "\n",
        "# Modify the number of classes from its default of 90\n",
        "model_config.ssd.num_classes = num_classes\n",
        "\n",
        "model_config.ssd.freeze_batchnorm = True\n",
        "model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kDwO8lAFc71"
      },
      "source": [
        "## Построение пользовательской модели\n",
        "\n",
        "Используем model_builder, который имеет функцию *build*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqe8zfOuEdK2",
        "outputId": "5e18eeaf-986e-4d44-969d-d7a3aa5c5e40"
      },
      "outputs": [],
      "source": [
        "detection_model = model_builder.build(\n",
        "    model_config, is_training= True\n",
        ")\n",
        "\n",
        "print(type(detection_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO7D7dOTFxo9"
      },
      "source": [
        "## Восстановление весов из контрольной точки\n",
        "\n",
        "Теперь выборочно восстановливаем веса из контрольной точки.\n",
        "- Конечная цель - создать пользовательскую модель, которая повторно использует некоторые слои RetinaNet (в настоящее время хранящиеся в переменной `detection_model`).\n",
        "  - Слои RetinaNet, которые будут использоваться повторно, это:\n",
        "    - Слои извлечения признаков\n",
        "    - Слой предсказания регрессии по граничным ячейкам\n",
        "  - Слой RetinaNet, которую не будет использоваться повторно, это слой прогнозирования классификации (так как будем определять и обучать собственный слой классификации, специфичный для оружия).\n",
        "  - Для слоев RetinaNet, которые будем использовать повторно, восстановливаем веса из контрольной точки, которую выбрали ранее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RPaNhvoFsAi",
        "outputId": "01f96fbb-effa-4fcd-8d8f-2eeb6b7d6367"
      },
      "outputs": [],
      "source": [
        "detection_model._box_predictor\n",
        "\n",
        "# View variables in _box_predictor\n",
        "vars(detection_model._box_predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgfJyORxGLEk"
      },
      "source": [
        "## Определение контрольных точек для предсказателя ячеек\n",
        "\n",
        "Определим box_predictor_checkpoint как контрольную точку для этих двух слоев предсказателя ячеек модели detection_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdBCk1dPGFFs"
      },
      "outputs": [],
      "source": [
        "tmp_box_predictor_checkpoint = tf.compat.v2.train.Checkpoint(\n",
        "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n",
        "    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n",
        "    )\n",
        "\n",
        "#Define the temporary model checkpoint\n",
        "tmp_model_checkpoint = tf.compat.v2.train.Checkpoint(\n",
        "          _feature_extractor=detection_model._feature_extractor,\n",
        "          _box_predictor=tmp_box_predictor_checkpoint)\n",
        "\n",
        "tmp_model_checkpoint = tf.compat.v2.train.Checkpoint(model=tmp_model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3xvO86VG-YZ"
      },
      "source": [
        "## Восстановление контрольной точки\n",
        "Сначала нужно найти и установить `checkpoint_path`.\n",
        "\n",
        "- checkpoint_path: \n",
        "  - Если была выполнена предыдущая ячейка кода, которая загружает и перемещает контрольную точку, то в результате её выполнения создается папка с именем \"checkpoint\".  \n",
        "    - Папка \"checkpoint\" содержит три файла:\n",
        "      - checkpoint\n",
        "      - ckpt-0.data-00000-of-00001\n",
        "      - ckpt-0.index\n",
        "    - В качестве checkpoint_path нужно установить полный путь, а точнее `models/.../ckpt-0`. \n",
        "      - Нужно обратить внимание, что нет необходимости указывать расширение файла после `ckpt-0`.\n",
        "\n",
        "Далее определяем последнюю контрольную точку, используя `tf.train.Checkpoint()`.\n",
        "- Для аргумента с одним ключевым словом, \n",
        "  - Задаем ключ как `model=` \n",
        "  - Устанавливаем значение временной контрольной точки модели, которую только что определили.\n",
        "- **ВАЖНО**: Нужно задать ключевое слово аргумента `model=`, а не что-то другое, например `detection_model=`.\n",
        "- Если задать этот ключевой аргумент каким-либо другим значением, это не приведет к немедленному появлению ошибки, но когда будет осуществляться процесс обучения модели на изображениях, потери модели не уменьшатся (модель не будет обучаться).\n",
        "\n",
        "Наконец, вызовем функцию `.restore()` этой контрольной точки, передав ей путь к контрольной точке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2L4GdO-Gs57",
        "outputId": "061c0047-5923-4a3c-e9f8-9de40dcd2a7b"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = 'models/research/object_detection/test_data/checkpoint/ckpt-0'\n",
        "\n",
        "checkpoint =tf.train.Checkpoint(model = detection_model) \n",
        "\n",
        "# Restore the checkpoint to the checkpoint path\n",
        "tmp_model_checkpoint.restore(checkpoint_path).expect_partial()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LyzzaPIHVyO"
      },
      "source": [
        "## Запуск фиктивного изображения для создания переменных модели\n",
        "\n",
        "Пропустим фиктивное изображение через модель, чтобы были созданы переменные. Нужно будет выбрать обучаемые переменные позже, а сейчас они все еще пусты. Если выполнить `len(detection_model.trainable_variables)`, то в ячейке кода получим `0`. Передадим фиктивное изображение через прямой проход, чтобы создать эти переменные.\n",
        "\n",
        "Важными методами, доступными в объекте `detection_model`, являются:\n",
        "- [preprocess()](https://github.com/tensorflow/models/blob/dc4d11216b738920ddb136729e3ae71bddb75c7e/research/object_detection/meta_architectures/ssd_meta_arch.py#L459): \n",
        "    - принимает тензор, представляющий изображение и возвращает его\n",
        "    - возвращает `изображения, формы`.\n",
        "    - для фиктивного изображения можно объявить [tensor of zeros](https://www.tensorflow.org/api_docs/python/tf/zeros), имеющий форму, которую может принять метод `preprocess()` (т.е. [партия, высота, ширина, каналы]). \n",
        "    - при создании фиктивного изображения можно передать партию, равную 1. \n",
        "\n",
        "- [predict()](https://github.com/tensorflow/models/blob/dc4d11216b738920ddb136729e3ae71bddb75c7e/research/object_detection/meta_architectures/ssd_meta_arch.py#L525)\n",
        "  - принимает `изображение, формы`, которые создаются вызовом функции `preprocess()`.\n",
        "  - возвращает предсказание в словаре Python.\n",
        "  - позволит пропустить фиктивное изображение через прямой проход сети и создать переменные модели\n",
        "\n",
        "- [postprocess()](https://github.com/tensorflow/models/blob/dc4d11216b738920ddb136729e3ae71bddb75c7e/research/object_detection/meta_architectures/ssd_meta_arch.py#L655)\n",
        "  - принимает prediction_dict и формы\n",
        "  - возвращает словарь постпроцессированных предсказаний обнаруженных объектов (\"detections\").\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZYnPCqWHQk5",
        "outputId": "daef3344-63a3-461a-e069-e8805719e6d4"
      },
      "outputs": [],
      "source": [
        "tmp_image, tmp_shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
        "tmp_prediction_dict = detection_model.predict(tmp_image, tmp_shapes)\n",
        "\n",
        "tmp_detections = detection_model.postprocess(tmp_prediction_dict, tmp_shapes)\n",
        "\n",
        "print('Weights restored!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgpeSeHTHo7_",
        "outputId": "dc7200c9-64e4-4c66-97b5-9029cde2d650"
      },
      "outputs": [],
      "source": [
        "#Set training hyperparameters\n",
        "tf.keras.backend.set_learning_phase(True)\n",
        "batch_size = 4\n",
        "\n",
        "num_batches = 100\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "# set the optimizer and pass in the learning_rate\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate= learning_rate, momentum= 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVOowzqYH1qp"
      },
      "outputs": [],
      "source": [
        "# define a list that contains the layers that  wish to fine tune\n",
        "trainable_variables = detection_model.trainable_variables\n",
        "to_fine_tune = []\n",
        "prefixes_to_train = [\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
        "for var in trainable_variables:\n",
        "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
        "    to_fine_tune.append(var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmRopFWoIJtD"
      },
      "source": [
        "## Обучение модели\n",
        "Определим функцию, которая обрабатывает обучение для одной партии, которую позже будем использовать в цикле обучения.\n",
        "\n",
        "Сначала пройдемся по ячейкам кода, чтобы узнать, как будем проводить обучение с помощью этой модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrUM22aFIAqT",
        "outputId": "9ee588d9-4e72-4ec3-be11-cff5cfd61680"
      },
      "outputs": [],
      "source": [
        "# Get a batch of your training images\n",
        "g_images_list = train_image_tensors[0:2]\n",
        "\n",
        "# Use .preprocess to preprocess an image\n",
        "g_preprocessed_image = detection_model.preprocess(g_images_list[0])\n",
        "print(f\"g_preprocessed_image type: {type(g_preprocessed_image)}\")\n",
        "print(f\"g_preprocessed_image length: {len(g_preprocessed_image)}\")\n",
        "print(f\"index 0 has the preprocessed image of shape {g_preprocessed_image[0].shape}\")\n",
        "print(f\"index 1 has information about the image's true shape excluding padding: {g_preprocessed_image[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiBDtKxBIfek"
      },
      "source": [
        "Можно предварительно обработать каждое изображение и сохранить результаты в два отдельных списка\n",
        "\n",
        "* Один список предварительно обработанных изображений.\n",
        "* Один список истинной формы для каждого предварительно обработанного изображения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_-pbjZcIbJ7"
      },
      "outputs": [],
      "source": [
        "preprocessed_image_list = []\n",
        "true_shape_list = []\n",
        "\n",
        "for img in g_images_list:\n",
        "    processed_img, true_shape = detection_model.preprocess(img)\n",
        "    preprocessed_image_list.append(processed_img)\n",
        "    true_shape_list.append(true_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCj3JsJ1Iu5k"
      },
      "source": [
        "## Предсказание\n",
        "В `detection_model` также есть функция `.predict`.  Согласно исходному коду для [predict](https://github.com/tensorflow/models/blob/dc4d11216b738920ddb136729e3ae71bddb75c7e/research/object_detection/meta_architectures/ssd_meta_arch.py#L525)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt_cEJOFInJK",
        "outputId": "ed98c1a1-69cb-48c1-ac02-65dda56842d2"
      },
      "outputs": [],
      "source": [
        "# Turn a list of tensors into a tensor\n",
        "preprocessed_image_tensor = tf.concat(preprocessed_image_list, axis=0)\n",
        "true_shape_tensor = tf.concat(true_shape_list, axis=0)\n",
        "\n",
        "# Make predictions on the images\n",
        "prediction_dict = detection_model.predict(preprocessed_image_tensor, true_shape_tensor)\n",
        "\n",
        "print(\"keys in prediction_dict:\")\n",
        "for key in prediction_dict.keys():\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ36zjTSI5bG"
      },
      "outputs": [],
      "source": [
        "# Get the ground truth bounding boxes\n",
        "gt_boxes_list = gt_box_tensors[0:2]\n",
        "\n",
        "# Get the ground truth class labels\n",
        "gt_classes_list = gt_classes_one_hot_tensors[0:2]\n",
        "\n",
        "# Provide the ground truth to the model\n",
        "detection_model.provide_groundtruth(\n",
        "            groundtruth_boxes_list=gt_boxes_list,\n",
        "            groundtruth_classes_list=gt_classes_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlPLPmC0JJnE"
      },
      "source": [
        "Теперь можно посчитать потери"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7D5fm8mJHG3",
        "outputId": "d20c9d8f-47de-489f-a892-178421b373de"
      },
      "outputs": [],
      "source": [
        "# Calculate the loss after you've provided the ground truth \n",
        "losses_dict = detection_model.loss(prediction_dict, true_shape_tensor)\n",
        "\n",
        "# View the loss dictionary\n",
        "losses_dict = detection_model.loss(prediction_dict, true_shape_tensor)\n",
        "print(f\"loss dictionary keys: {losses_dict.keys()}\")\n",
        "print(f\"localization loss {losses_dict['Loss/localization_loss']:.8f}\")\n",
        "print(f\"classification loss {losses_dict['Loss/classification_loss']:.8f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plcGcmuBJVhE"
      },
      "source": [
        "## Определение одного шага обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2FNviqHJLbJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# decorate with @tf.function for faster training (remember, graph mode!)\n",
        "@tf.function\n",
        "def train_step_fn(image_list,\n",
        "                groundtruth_boxes_list,\n",
        "                groundtruth_classes_list,\n",
        "                model,\n",
        "                optimizer,\n",
        "                vars_to_fine_tune):\n",
        "\n",
        "    shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\n",
        "    model.provide_groundtruth(\n",
        "        groundtruth_boxes_list=groundtruth_boxes_list,\n",
        "        groundtruth_classes_list=groundtruth_classes_list)\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Preprocess the images\n",
        "        \n",
        "        preprocessed_image_tensor = tf.concat(\n",
        "            [detection_model.preprocess(image_tensor)[0]\n",
        "             for image_tensor in image_list], axis=0) \n",
        "        true_shape_tensor = preprocessed_image_tensor.shape \n",
        "\n",
        "        # Make a prediction\n",
        "        prediction_dict = model.predict(preprocessed_image_tensor, shapes)\n",
        "\n",
        "        # Calculate the total loss (sum of both losses)\n",
        "        losses_dict = model.loss(prediction_dict, shapes)\n",
        "        total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
        "\n",
        "        # Calculate the gradients\n",
        "        gradients = tape.gradient(total_loss, vars_to_fine_tune)\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n",
        "        \n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvRECPcNJowz"
      },
      "source": [
        "## Запуск цикла обучения\n",
        "\n",
        "Запустим цикл обучения, используя функцию шага обучения, которую определили ранее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgqWjcDHJi8e",
        "outputId": "920ef4c9-8161-4f71-d3b8-e338717c80b3"
      },
      "outputs": [],
      "source": [
        "print('Start', flush=True)\n",
        "\n",
        "for idx in range(num_batches):\n",
        "    all_keys = list(range(len(train_images_np)))\n",
        "    random.shuffle(all_keys)\n",
        "    example_keys = all_keys[:batch_size]\n",
        "\n",
        "    # Get the ground truth\n",
        "    gt_boxes_list = [gt_box_tensors[key] for key in example_keys]\n",
        "    gt_classes_list = [gt_classes_one_hot_tensors[key] for key in example_keys]\n",
        "    \n",
        "    # get the images\n",
        "    image_tensors = [train_image_tensors[key] for key in example_keys]\n",
        "\n",
        "    # Training step (forward pass + backwards pass)\n",
        "    total_loss = train_step_fn(image_tensors, \n",
        "                               gt_boxes_list, \n",
        "                               gt_classes_list,\n",
        "                               detection_model,\n",
        "                               optimizer,\n",
        "                               to_fine_tune\n",
        "                              )\n",
        "\n",
        "    if idx % 10 == 0:\n",
        "        print('batch ' + str(idx) + ' of ' + str(num_batches)\n",
        "        + ', loss=' +  str(total_loss.numpy()), flush=True)\n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhao6Rt1J3BS"
      },
      "source": [
        "## Загрузка тестовых изображений и запуск вывода с новой моделью\n",
        "\n",
        "Теперь протестируем модель на новом наборе изображений, которые хранятся в каталоге result. В ячейке ниже эти изображения загружаются в массивы numpy, чтобы подготовить их к выводу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfKVcFlnJyuy",
        "outputId": "828ca96d-d0c0-48b6-fe19-91583fb99f1b"
      },
      "outputs": [],
      "source": [
        "test_image_dir = './result/'\n",
        "test_images_np = []\n",
        "\n",
        "# load images into a numpy array. this will take a few minutes to complete.\n",
        "for i in range(0, 2):\n",
        "    image_path = os.path.join(test_image_dir, 'test' + \"{0:04}\".format(i) + '.jpeg')\n",
        "    print(image_path)\n",
        "    test_images_np.append(np.expand_dims(\n",
        "      load_image_into_numpy_array(image_path), axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50VBILaNLx1h"
      },
      "outputs": [],
      "source": [
        "#  Preprocess, predict, and post process an image\n",
        "\n",
        "# Again, uncomment this decorator if you want to run inference eagerly\n",
        "@tf.function\n",
        "def detect(input_tensor):\n",
        "\n",
        "    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
        "    prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
        "\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    \n",
        "    return detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUQ5EpulMBmi"
      },
      "outputs": [],
      "source": [
        "label_id_offset = 1\n",
        "results1 = {'boxes': [], 'scores': []}\n",
        "\n",
        "for i in range(len(test_images_np)):\n",
        "    input_tensor = tf.convert_to_tensor(test_images_np[i], dtype=tf.float32)\n",
        "    detections = detect(input_tensor)\n",
        "    plot_detections(\n",
        "      test_images_np[i][0],\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      detections['detection_classes'][0].numpy().astype(np.uint32)\n",
        "      + label_id_offset,\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index, figsize=(15, 20), image_name=\"./result/gif_frame_\" + ('%04d' % i) + \".jpg\")\n",
        "    results1['boxes'].append(detections['detection_boxes'][0][0].numpy())\n",
        "    results1['scores'].append(detections['detection_scores'][0][0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miiyOQ8BMeSM"
      },
      "source": [
        "Также можно проверить, обнаруживает ли модель класс оружия на изображениях, изучив значение ключа scores в словаре результатов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzI2zp1sMbCD",
        "outputId": "141bcaed-7364-4ab6-8719-c2410032e5ec"
      },
      "outputs": [],
      "source": [
        "x = np.array(results1['scores'])\n",
        "\n",
        "# percent of frames where a gun is detected\n",
        "gun_detected = (np.where(x > 0.9, 1, 0).sum())/237*100\n",
        "print(gun_detected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRUA5RuYMqYW"
      },
      "source": [
        "Есть возможность показать несколько стоп-кадров и провести визуальный осмотр. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "S2ypYUaEMrzY",
        "outputId": "d018c824-2a5f-4fba-936d-38fdcf6cb584"
      },
      "outputs": [],
      "source": [
        "print('Frame 0')\n",
        "display(IPyImage('./result/gif_frame_0001.jpg'))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "njpHryaHPMsV",
        "outputId": "b53af0fd-6835-4d7f-855b-727b1a8559e9"
      },
      "outputs": [],
      "source": [
        "print('Frame 1')\n",
        "display(IPyImage('./result/gif_frame_0000.jpg'))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zO5g07hwQHO1",
        "outputId": "ccd94484-e128-47f3-f034-c138735b9948"
      },
      "outputs": [],
      "source": [
        "#Save results\n",
        "import pickle\n",
        "\n",
        "with open('results.data', 'wb') as filehandle:\n",
        "    pickle.dump(results1['boxes'], filehandle)\n",
        "\n",
        "#from google.colab import files\n",
        "#files.download('results.data')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Weapon_Detection_with_TensorFlow.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "eba8258abf1971a84eb7393edfa2cbc02ef47c11356b40870910fb3f775b45fb"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('3.9.5': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}